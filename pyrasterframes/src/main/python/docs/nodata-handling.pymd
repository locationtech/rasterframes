# "NoData" Handling

## What is NoData?

In raster operations, the preservation and correct processing of missing observations is very important. In [most DataFrames and scientific computing](https://www.oreilly.com/learning/handling-missing-data), the idea of missing data is expressed as a `null` or `NaN` value. A great deal of raster data is stored for space efficiency. This typically leads to use of integral values and a "sentinel" value to represent missing observations. This sentinel value varies across data products and is usually called the "NoData" value.

RasterFrames provides a variety of functions to inspect and manage NoData within `tile`s.

## Cell Types

To understand how NoData is handled in RasterFrames, we first need to understand the different underlying types of data called cell types. The cell types are GeoTrellis `CellType`s, so the [GeoTrellis documentation](https://geotrellis.readthedocs.io/en/latest/guide/core-concepts.html?#working-with-cell-values) is a valuable resource on how these are defined.

```python setup, echo=False
import pyrasterframes
from pyrasterframes.rasterfunctions import *
import pyrasterframes.rf_ipython
from IPython.display import display
import pandas as pd
import numpy as np
from pyrasterframes.rf_types import Tile

spark = pyrasterframes.get_spark_session()
```

The `CellType` class from the `rf_types` submodule allows us to create a representation of any valid cell type. There are convenience methods to create instances for a variety of basic types.

```python celltype_ctors
from pyrasterframes.rf_types import CellType
import inspect

[c[0] for c in inspect.getmembers(CellType, inspect.ismethod)]
```

We can also inspect the cell type of a given _tile_ or `proj_raster` column.

```python ct_from_sen
spark.read.raster('https://s22s-test-geotiffs.s3.amazonaws.com/luray_snp/B02.tif') \
    .select(rf_cell_type('proj_raster')).distinct().show()
```

### Understanding Cell Types and NoData

We can use the methods on the `CellType` class to learn more about a specific cell type. Let's consider the cell type of our sample data above.

```python
ct = CellType('uint16raw')
ct, ct.is_floating_point(), ct.has_no_data()
```

We can see that for the above data source, there is no defined NoData value. This means that each value is interpreted as a valid observation. Often such data is meant to be combined with another band indicating the quality of observations at each location. The lack of NoData is indicated by the `raw` at the end of the type name. Consider also the `uint16` cell type.

```python
from pyrasterframes.rf_types import CellType
ct = CellType('uint16')
ct, ct.is_floating_point(), ct.has_no_data(), ct.no_data_value()
```

In this case, the minimum value of 0 is designated as the NoData value. For integral-valued cell types, the NoData is typically zero, the maximum, or the minimum value for the underlying data type. The NoData value can also be a user-defined value. In that case the value is designated with a `ud`.

```python
CellType.uint16().with_no_data_value(99).cell_type_name
```

Floating point types have `NaN` as the NoData value by default. However, a user-defined NoData can be set.

```python float_ud
print(CellType.float32().no_data_value())
print(CellType.float32().with_no_data_value(-99.9).no_data_value())
```

## Masking

Let's continue the example above with Sentinel-2 data. Band 2 is blue and has no defined NoData. The quality information is in a separate file called the scene classification (SCL), which delineates areas of missing data and probable clouds. For more information on that, see the [Sentinel-2 algorithm overview](https://earth.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm). Figure 3 tells us how to interpret the scene classification. For this example, we will exclude NoData, defective pixels, probable clouds, and cirrus clouds: values 0, 1, 8, 9, and 10.

![Sentinel-2 Scene Classification Values](static/sentinel-2-scene-classification-labels.png)
Credit: [Sentinel-2 algorithm overview](https://earth.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm)

The first step is to create a catalog with our band of interest and the SCL band. We read the data from the catalog, so the blue band and SCL tiles are aligned across rows.

```python blue_scl_cat
from pyspark.sql import Row

blue_uri = 'https://s22s-test-geotiffs.s3.amazonaws.com/luray_snp/B02.tif'
scl_uri = 'https://s22s-test-geotiffs.s3.amazonaws.com/luray_snp/SCL.tif'
cat = spark.createDataFrame([Row(blue=blue_uri, scl=scl_uri),])
unmasked = spark.read.raster(catalog=cat, catalog_col_names=['blue', 'scl'])
unmasked.printSchema()
unmasked.select(rf_cell_type('blue'), rf_cell_type('scl')).distinct().show()
```

Drawing on @ref:[local map algebra](local-algebra.md) techniques, we will create new tile columns that are indicators of unwanted pixels, as defined above. Since the mask column is bit type, the addition is equivalent to a logical or, so the true values are 1.

```python def_mask
from pyspark.sql.functions import lit

mask_part = unmasked.withColumn('nodata', rf_local_equal('scl', lit(0))) \
                    .withColumn('defect', rf_local_equal('scl', lit(1))) \
                    .withColumn('cloud8', rf_local_equal('scl', lit(8))) \
                    .withColumn('cloud9', rf_local_equal('scl', lit(9))) \
                    .withColumn('cirrus', rf_local_equal('scl', lit(10)))

one_mask = mask_part.withColumn('mask', rf_local_add('nodata', 'defect')) \
                    .withColumn('mask', rf_local_add('mask', 'cloud8')) \
                    .withColumn('mask', rf_local_add('mask', 'cloud9')) \
                    .withColumn('mask', rf_local_add('mask', 'cirrus'))

one_mask.select(rf_cell_type('mask')).distinct().show()
```

Because there is not a NoData already defined, we will choose one. In this particular example, the minimum value is greater than zero, so we can use 0 as the NoData value.

```python pick_nd
one_mask.agg(rf_agg_stats('blue').min.alias('blue_min')).show()
```

We can now construct the cell type string for our blue band's cell type, designating 0 as NoData.

```python get_ct_string
blue_ct = one_mask.select(rf_cell_type('blue')).distinct().first()[0][0]
masked_blue_ct = CellType(blue_ct).with_no_data_value(0)
masked_blue_ct.cell_type_name
```

Now we will use the @ref:[`rf_mask_by_value`](reference.md#rf-mask-by-value) to designate the cloudy and other unwanted pixels as NoData in the blue column by converting the cell type and applying the mask.

```python mask_blu
with_nd = rf_convert_cell_type('blue', masked_blue_ct.cell_type_name)
masked = one_mask.withColumn('blue_masked',
                             rf_mask_by_value(with_nd, 'mask', lit(1))) \
                 .drop('nodata', 'defect', 'cloud8', 'cloud9', 'cirrus', 'blue')
```

We can verify that the number of NoData cells in the resulting `blue_masked` column matches the total of the bit-type `mask` tile to ensure our logic is correct.

```python
masked.select(rf_no_data_cells('blue_masked'), rf_tile_sum('mask')).show(10)
```

It's also nice to view a sample. The white regions are areas of NoData.

```python, caption='Blue band masked against selected SCL values'
sample = masked.orderBy(-rf_no_data_cells('blue_masked')).select(rf_tile('blue_masked'), rf_tile('scl')).first()
display(sample[0])
```

And the original SCL data. The bright yellow is a cloudy region in the original image.

```python, caption='SCL tile for above'
display(sample[1])
```

## NoData and Local Arithmatic

Let's now explore how the presence of NoData affects @ref:[local map algebra](local-algebra.md) operations. To demonstrate the behaviour, lets create two tiles. One tile will have values of 0 and 1, and the other will have values of just 0.


```python
tile_size = 100
x = np.zeros((tile_size, tile_size), dtype='int16')
x[:,tile_size//2:] = 1
x = Tile(x)
y = Tile(np.zeros((tile_size, tile_size), dtype='int16'))

rf = spark.createDataFrame([Row(x=x, y=y)])
print('x')
display(x)
```

```python
print('y')
display(y)
```

Now, let's create a new column from `x` with the value of 1 changed to NoData. Then, we will add this new column with NoData to the `y` column. As shown below, the result of the sum also has NoData (represented in white). In general for local algebra operations, Data + NoData = NoData.

```python
masked_rf = rf.withColumn('x_nd', rf_mask_by_value('x', 'x', lit(1)) )
masked_rf = masked_rf.withColumn('x_nd_y_sum', rf_local_add('x_nd', 'y'))
row = masked_rf.collect()[0]
print('x with NoData')
display(row.x_nd)
```

```python
print('x with NoData plus y')
display(row.x_nd_y_sum)
```
To see more information about possible operations on Tile columns, see the @ref:[local map algebra](local-algebra.md) page and @ref:[function reference](reference.md#local-map-algebra).

## Changing a Tile's NoData Values

One way to mask a tile is to make a new tile with a user defined NoData value. We will explore this method below. First, lets create a DataFrame from a tile with values of 0, 1, 2, and 3. We will use numpy to create a 100x100 Tile with vertical bands containing values 0, 1, 2, and 3.

```python create_dummy_tile, caption='Dummy Tile'
tile_size = 100
x = np.zeros((tile_size, tile_size), dtype='int16')

# setting the values of the columns
for i in range(4):
    x[:, i*tile_size//4:(i+1)*tile_size//4] = i
x = Tile(x)

rf = spark.createDataFrame([Row(tile=x)])
display(x)
```

First, we mask the value of 1 by making a new column with the user defined cell type 'uint16ud1'. Then, we mask out the value of two by making a tile with the cell type 'uint16ud2'.

```python
def get_nodata_ct(nd_val):
	return CellType('uint16').with_no_data_value(nd_val)

masked_rf = rf.withColumn('tile_nd_1',
                           rf_convert_cell_type('tile', get_nodata_ct(1))) \
              .withColumn('tile_nd_2',
                          rf_convert_cell_type('tile_nd_1', get_nodata_ct(2))) \
```

```python
collected = masked_rf.collect()
```

Let's look at the new Tiles we created. The tile named `tile_nd_1` has the 1 values masked out as expected.

```python
display(collected[0].tile_nd_1)
```

And the tile named `tile_nd_2` has the values of 1 and 2 masked out. This is because we created the tile by setting a new user defined NoData value to `tile_nd_1` the values previously masked out in `tile_nd_1` stayed masked when creating `tile_nd_2`.

```python
display(collected[0].tile_nd_2)
```


## Combining Tiles with Different Data Types

RasterFrames supports having Tile columns with multiple cell types in a single DataFrame. It is important to understand how these different cell types interact.

Let's first create a RasterFrame that has columns of `float` and `int` cell type.

```python
x = Tile((np.ones((100, 100))*2).astype('float'))
y = Tile((np.ones((100, 100))*3.0).astype('int32'))
rf = spark.createDataFrame([Row(x=x, y=y)])

rf.select(rf_cell_type('x'), rf_cell_type('y')).distinct().show()
```

When performing a local operation between tile columns with cell types `int` and type `float`, the resulting tile cell type will be `float`. In local algebra over two tiles of different "sized" cell types, the resulting cell type will be the largest of the two input tiles' cell types.

```python
rf.select(
    rf_cell_type('x'),
    rf_cell_type('y'),
    rf_cell_type(rf_local_add('x', 'y').alias('xy_sum')),
    ).show(1)
```

Combining tile columns of different cell types gets a little trickier when user defined NoData cell types are involved. Let's create 2 tile columns: one with a NoData value of 1, and one with a NoData value of 2.

```python
x_nd_1 = Tile((np.ones((100, 100))*3), get_nodata_ct(1))
x_nd_2 = Tile((np.ones((100, 100))*3), get_nodata_ct(2))
rf_nd = spark.createDataFrame([Row(x_nd_1=x_nd_1, x_nd_2=x_nd_2)])
```

Let's try adding the tile columns with different NoData values. When there is an inconsistent NoData value in the two columns, the NoData value of the right-hand side of the sum is kept. In this case, this means the result has a NoData value of 1.

```python
rf_nd_sum = rf_nd.withColumn('x_nd_sum', rf_local_add('x_nd_2', 'x_nd_1'))
rf_nd_sum.select(rf_cell_type('x_nd_sum')).distinct().show()
```

Reversing the order of the sum changes the NoData value of the resulting column to 2.

```python
rf_nd_sum = rf_nd.withColumn('x_nd_sum', rf_local_add('x_nd_1', 'x_nd_2'))
rf_nd_sum.select(rf_cell_type('x_nd_sum')).distinct().show()
```

## NoData Values in Aggregation

Let's use the same tile as before to demonstrate how NoData values affect tile aggregations.

```python
tile_size = 100
x = np.zeros((tile_size, tile_size), dtype='int16')
for i in range(4):
    x[:, i*tile_size//4:(i+1)*tile_size//4] = i
x = Tile(x)

rf = spark.createDataFrame([Row(tile=x)])
display(x)
```

First we create the two new masked tile columns as before. One with only the value of 1 masked, and the other with and values of 1 and 2 masked.

```python
masked_rf = rf.withColumn('tile_nd_1',
                           rf_convert_cell_type('tile', get_nodata_ct(1))) \
              .withColumn('tile_nd_2',
                          rf_convert_cell_type('tile_nd_1', get_nodata_ct(2)))
```

The results of `rf_tile_sum` vary on the tiles that were masked. This is because any cells with NoData values are ignored in the aggregation. Note that `tile_nd_2` has the lowest sum, since it has the fewest amount of data cells.

```python
masked_rf.select(rf_tile_sum('tile'), rf_tile_sum('tile_nd_1'), rf_tile_sum('tile_nd_2')).show()
```
